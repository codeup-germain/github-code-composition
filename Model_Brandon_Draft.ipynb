{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44ca195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from prepare import prepare\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# imports for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bab94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab49decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217978c",
   "metadata": {},
   "source": [
    "# Check out prepare for prepare details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b163b7c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train,validate,test = prepare(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a76e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Asabeneh/30-Days-Of-JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># 30 Days Of JavaScript\\n\\n| # Day |          ...</td>\n",
       "      <td>30 days javascript day topics 01 introductionr...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MrS0m30n3/youtube-dl-gui</td>\n",
       "      <td>Python</td>\n",
       "      <td>[![Donations Badge](https://yourdonation.rocks...</td>\n",
       "      <td>donations badgehttpsyourdonationrocksimagesbad...</td>\n",
       "      <td>donat badgehttpsyourdonationrocksimagesbadgesv...</td>\n",
       "      <td>donation badgehttpsyourdonationrocksimagesbadg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>statianzo/Fleck</td>\n",
       "      <td>C#</td>\n",
       "      <td>Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ddbourgin/numpy-ml</td>\n",
       "      <td>Python</td>\n",
       "      <td># numpy-ml\\nEver wish you had an inefficient b...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "      <td>numpyml ever wish ineffici somewhat legibl col...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mono/CppSharp</td>\n",
       "      <td>C#</td>\n",
       "      <td>CppSharp is a tool and set of libraries which ...</td>\n",
       "      <td>cppsharp tool set libraries facilitates usage ...</td>\n",
       "      <td>cppsharp tool set librari facilit usag nativ c...</td>\n",
       "      <td>cppsharp tool set library facilitates usage na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo    language  \\\n",
       "63  Asabeneh/30-Days-Of-JavaScript  JavaScript   \n",
       "18        MrS0m30n3/youtube-dl-gui      Python   \n",
       "72                 statianzo/Fleck          C#   \n",
       "12              ddbourgin/numpy-ml      Python   \n",
       "88                   mono/CppSharp          C#   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "63  # 30 Days Of JavaScript\\n\\n| # Day |          ...   \n",
       "18  [![Donations Badge](https://yourdonation.rocks...   \n",
       "72  Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...   \n",
       "12  # numpy-ml\\nEver wish you had an inefficient b...   \n",
       "88  CppSharp is a tool and set of libraries which ...   \n",
       "\n",
       "                                                clean  \\\n",
       "63  30 days javascript day topics 01 introductionr...   \n",
       "18  donations badgehttpsyourdonationrocksimagesbad...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish inefficient somewhat legible...   \n",
       "88  cppsharp tool set libraries facilitates usage ...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "63  30 day javascript day topic 01 introductionrea...   \n",
       "18  donat badgehttpsyourdonationrocksimagesbadgesv...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish ineffici somewhat legibl col...   \n",
       "88  cppsharp tool set librari facilit usag nativ c...   \n",
       "\n",
       "                                           lemmatized  \n",
       "63  30 day javascript day topic 01 introductionrea...  \n",
       "18  donation badgehttpsyourdonationrocksimagesbadg...  \n",
       "72  fleck build statushttpsciappveyorcomapiproject...  \n",
       "12  numpyml ever wish inefficient somewhat legible...  \n",
       "88  cppsharp tool set library facilitates usage na...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5200047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 6), (25, 6), (21, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027512fd",
   "metadata": {},
   "source": [
    "# No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b4b85",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5495f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    \n",
    "    ADDITIONAL_STOPWORDS = []\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a026e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C#</th>\n",
       "      <td>18</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>14</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>13</td>\n",
       "      <td>0.224138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>13</td>\n",
       "      <td>0.224138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n   percent\n",
       "C#          18  0.310345\n",
       "HTML        14  0.241379\n",
       "JavaScript  13  0.224138\n",
       "Python      13  0.224138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_counts_and_ratios(df, column):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a string of a single column\n",
    "    Returns a dataframe with absolute value counts and percentage value counts\n",
    "    \"\"\"\n",
    "    labels = pd.concat([df[column].value_counts(),\n",
    "                    df[column].value_counts(normalize=True)], axis=1)\n",
    "    labels.columns = ['n', 'percent']\n",
    "    labels\n",
    "    return labels\n",
    "\n",
    "show_counts_and_ratios(train, \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432da734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Asabeneh/30-Days-Of-JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># 30 Days Of JavaScript\\n\\n| # Day |          ...</td>\n",
       "      <td>30 days javascript day topics 01 introductionr...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MrS0m30n3/youtube-dl-gui</td>\n",
       "      <td>Python</td>\n",
       "      <td>[![Donations Badge](https://yourdonation.rocks...</td>\n",
       "      <td>donations badgehttpsyourdonationrocksimagesbad...</td>\n",
       "      <td>donat badgehttpsyourdonationrocksimagesbadgesv...</td>\n",
       "      <td>donation badgehttpsyourdonationrocksimagesbadg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>statianzo/Fleck</td>\n",
       "      <td>C#</td>\n",
       "      <td>Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ddbourgin/numpy-ml</td>\n",
       "      <td>Python</td>\n",
       "      <td># numpy-ml\\nEver wish you had an inefficient b...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "      <td>numpyml ever wish ineffici somewhat legibl col...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mono/CppSharp</td>\n",
       "      <td>C#</td>\n",
       "      <td>CppSharp is a tool and set of libraries which ...</td>\n",
       "      <td>cppsharp tool set libraries facilitates usage ...</td>\n",
       "      <td>cppsharp tool set librari facilit usag nativ c...</td>\n",
       "      <td>cppsharp tool set library facilitates usage na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo    language  \\\n",
       "63  Asabeneh/30-Days-Of-JavaScript  JavaScript   \n",
       "18        MrS0m30n3/youtube-dl-gui      Python   \n",
       "72                 statianzo/Fleck          C#   \n",
       "12              ddbourgin/numpy-ml      Python   \n",
       "88                   mono/CppSharp          C#   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "63  # 30 Days Of JavaScript\\n\\n| # Day |          ...   \n",
       "18  [![Donations Badge](https://yourdonation.rocks...   \n",
       "72  Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...   \n",
       "12  # numpy-ml\\nEver wish you had an inefficient b...   \n",
       "88  CppSharp is a tool and set of libraries which ...   \n",
       "\n",
       "                                                clean  \\\n",
       "63  30 days javascript day topics 01 introductionr...   \n",
       "18  donations badgehttpsyourdonationrocksimagesbad...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish inefficient somewhat legible...   \n",
       "88  cppsharp tool set libraries facilitates usage ...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "63  30 day javascript day topic 01 introductionrea...   \n",
       "18  donat badgehttpsyourdonationrocksimagesbadgesv...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish ineffici somewhat legibl col...   \n",
       "88  cppsharp tool set librari facilit usag nativ c...   \n",
       "\n",
       "                                           lemmatized  \n",
       "63  30 day javascript day topic 01 introductionrea...  \n",
       "18  donation badgehttpsyourdonationrocksimagesbadg...  \n",
       "72  fleck build statushttpsciappveyorcomapiproject...  \n",
       "12  numpyml ever wish inefficient somewhat legible...  \n",
       "88  cppsharp tool set library facilitates usage na...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68269e79",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf65230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy:C# 31%\n"
     ]
    }
   ],
   "source": [
    "#Create a baseline model\n",
    "\n",
    "print(f'Baseline Accuracy:{train.language.value_counts().idxmax()} {round(max(train.language.value_counts()) / train.shape[0] *100)}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccee36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_split(x):   \n",
    "    vectorizer = CountVectorizer(binary = True, stop_words = 'english')\n",
    "    vectorizer.fit(list(train[x]))\n",
    "    X_train = vectorizer.transform(train[x])\n",
    "    X_validate= vectorizer.transform(validate[x])\n",
    "    X_test = vectorizer.transform(test[x])\n",
    "    return X_train.todense(),X_validate.todense(),X_test.todense()\n",
    "\n",
    "def tfidf_split(x):   \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(list(train[x]))\n",
    "    X_train = tfidf.transform(train[x])\n",
    "    X_validate= tfidf.transform(validate[x])\n",
    "    X_test = tfidf.transform(test[x])\n",
    "    return X_train.todense(),X_validate.todense(),X_test.todense()\n",
    "\n",
    "def test_a_model(X_train, y_train, X_validate, y_validate, model, model_name, score_df):\n",
    "    '''\n",
    "    Function takes in X and y train\n",
    "    X and y validate (or test) \n",
    "    A model with it's hyper parameters\n",
    "    And a df to store the scores \n",
    "    - Set up an empty dataframe with score_df first\n",
    "    - score_df = pd.DataFrame(columns = ['model_name', 'train_score', 'validate_score'])\n",
    "    '''\n",
    "    this_model = model\n",
    "\n",
    "    this_model.fit(X_train, y_train)\n",
    "\n",
    "    # Check with Validate\n",
    "\n",
    "    train_score = this_model.score(X_train, y_train)\n",
    "    \n",
    "    validate_score = this_model.score(X_validate, y_validate)\n",
    "    \n",
    "    model_dict = {'model_name': model_name, \n",
    "                  'train_score': train_score, \n",
    "                  'validate_score':validate_score}\n",
    "    score_df = score_df.append(model_dict, ignore_index = True)\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "513c5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.language\n",
    "y_validate = validate.language\n",
    "y_test = test.language\n",
    "X_train,X_validate,X_test = vectorizer_split('clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf37d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = vectorizer_split('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52fceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(columns = ['model_name', 'train_score', 'validate_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d9f3700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_53915_row1_col5{\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_53915_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >max_depth</th>        <th class=\"col_heading level0 col1\" >train_accuracy</th>        <th class=\"col_heading level0 col2\" >validate_accuracy</th>        <th class=\"col_heading level0 col3\" >train_recall</th>        <th class=\"col_heading level0 col4\" >validate_recall</th>        <th class=\"col_heading level0 col5\" >accuracy_difference</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_53915_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_53915_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "                        <td id=\"T_53915_row0_col1\" class=\"data row0 col1\" >0.741000</td>\n",
       "                        <td id=\"T_53915_row0_col2\" class=\"data row0 col2\" >0.280000</td>\n",
       "                        <td id=\"T_53915_row0_col3\" class=\"data row0 col3\" >0.741000</td>\n",
       "                        <td id=\"T_53915_row0_col4\" class=\"data row0 col4\" >0.280000</td>\n",
       "                        <td id=\"T_53915_row0_col5\" class=\"data row0 col5\" >0.461000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_53915_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "                        <td id=\"T_53915_row1_col1\" class=\"data row1 col1\" >0.862000</td>\n",
       "                        <td id=\"T_53915_row1_col2\" class=\"data row1 col2\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row1_col3\" class=\"data row1 col3\" >0.862000</td>\n",
       "                        <td id=\"T_53915_row1_col4\" class=\"data row1 col4\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row1_col5\" class=\"data row1 col5\" >0.382000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_53915_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "                        <td id=\"T_53915_row2_col1\" class=\"data row2 col1\" >0.897000</td>\n",
       "                        <td id=\"T_53915_row2_col2\" class=\"data row2 col2\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row2_col3\" class=\"data row2 col3\" >0.897000</td>\n",
       "                        <td id=\"T_53915_row2_col4\" class=\"data row2 col4\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row2_col5\" class=\"data row2 col5\" >0.417000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_53915_row3_col0\" class=\"data row3 col0\" >5</td>\n",
       "                        <td id=\"T_53915_row3_col1\" class=\"data row3 col1\" >0.931000</td>\n",
       "                        <td id=\"T_53915_row3_col2\" class=\"data row3 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row3_col3\" class=\"data row3 col3\" >0.931000</td>\n",
       "                        <td id=\"T_53915_row3_col4\" class=\"data row3 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row3_col5\" class=\"data row3 col5\" >0.411000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_53915_row4_col0\" class=\"data row4 col0\" >6</td>\n",
       "                        <td id=\"T_53915_row4_col1\" class=\"data row4 col1\" >0.966000</td>\n",
       "                        <td id=\"T_53915_row4_col2\" class=\"data row4 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row4_col3\" class=\"data row4 col3\" >0.966000</td>\n",
       "                        <td id=\"T_53915_row4_col4\" class=\"data row4 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row4_col5\" class=\"data row4 col5\" >0.446000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_53915_row5_col0\" class=\"data row5 col0\" >7</td>\n",
       "                        <td id=\"T_53915_row5_col1\" class=\"data row5 col1\" >0.966000</td>\n",
       "                        <td id=\"T_53915_row5_col2\" class=\"data row5 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row5_col3\" class=\"data row5 col3\" >0.966000</td>\n",
       "                        <td id=\"T_53915_row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row5_col5\" class=\"data row5 col5\" >0.446000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_53915_row6_col0\" class=\"data row6 col0\" >8</td>\n",
       "                        <td id=\"T_53915_row6_col1\" class=\"data row6 col1\" >0.983000</td>\n",
       "                        <td id=\"T_53915_row6_col2\" class=\"data row6 col2\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row6_col3\" class=\"data row6 col3\" >0.983000</td>\n",
       "                        <td id=\"T_53915_row6_col4\" class=\"data row6 col4\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row6_col5\" class=\"data row6 col5\" >0.383000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_53915_row7_col0\" class=\"data row7 col0\" >9</td>\n",
       "                        <td id=\"T_53915_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row7_col2\" class=\"data row7 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row7_col4\" class=\"data row7 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row7_col5\" class=\"data row7 col5\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_53915_row8_col0\" class=\"data row8 col0\" >10</td>\n",
       "                        <td id=\"T_53915_row8_col1\" class=\"data row8 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row8_col2\" class=\"data row8 col2\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row8_col3\" class=\"data row8 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row8_col4\" class=\"data row8 col4\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row8_col5\" class=\"data row8 col5\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_53915_row9_col0\" class=\"data row9 col0\" >11</td>\n",
       "                        <td id=\"T_53915_row9_col1\" class=\"data row9 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row9_col2\" class=\"data row9 col2\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row9_col3\" class=\"data row9 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row9_col4\" class=\"data row9 col4\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row9_col5\" class=\"data row9 col5\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_53915_row10_col0\" class=\"data row10 col0\" >12</td>\n",
       "                        <td id=\"T_53915_row10_col1\" class=\"data row10 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row10_col2\" class=\"data row10 col2\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row10_col3\" class=\"data row10 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row10_col4\" class=\"data row10 col4\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row10_col5\" class=\"data row10 col5\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_53915_row11_col0\" class=\"data row11 col0\" >13</td>\n",
       "                        <td id=\"T_53915_row11_col1\" class=\"data row11 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row11_col2\" class=\"data row11 col2\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row11_col3\" class=\"data row11 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row11_col4\" class=\"data row11 col4\" >0.600000</td>\n",
       "                        <td id=\"T_53915_row11_col5\" class=\"data row11 col5\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_53915_row12_col0\" class=\"data row12 col0\" >14</td>\n",
       "                        <td id=\"T_53915_row12_col1\" class=\"data row12 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row12_col2\" class=\"data row12 col2\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row12_col3\" class=\"data row12 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row12_col4\" class=\"data row12 col4\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row12_col5\" class=\"data row12 col5\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_53915_row13_col0\" class=\"data row13 col0\" >15</td>\n",
       "                        <td id=\"T_53915_row13_col1\" class=\"data row13 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row13_col2\" class=\"data row13 col2\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row13_col3\" class=\"data row13 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row13_col4\" class=\"data row13 col4\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row13_col5\" class=\"data row13 col5\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_53915_row14_col0\" class=\"data row14 col0\" >16</td>\n",
       "                        <td id=\"T_53915_row14_col1\" class=\"data row14 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row14_col2\" class=\"data row14 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row14_col3\" class=\"data row14 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row14_col4\" class=\"data row14 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row14_col5\" class=\"data row14 col5\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_53915_row15_col0\" class=\"data row15 col0\" >17</td>\n",
       "                        <td id=\"T_53915_row15_col1\" class=\"data row15 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row15_col2\" class=\"data row15 col2\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row15_col3\" class=\"data row15 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row15_col4\" class=\"data row15 col4\" >0.560000</td>\n",
       "                        <td id=\"T_53915_row15_col5\" class=\"data row15 col5\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_53915_row16_col0\" class=\"data row16 col0\" >18</td>\n",
       "                        <td id=\"T_53915_row16_col1\" class=\"data row16 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row16_col2\" class=\"data row16 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row16_col3\" class=\"data row16 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row16_col4\" class=\"data row16 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row16_col5\" class=\"data row16 col5\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_53915_row17_col0\" class=\"data row17 col0\" >19</td>\n",
       "                        <td id=\"T_53915_row17_col1\" class=\"data row17 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row17_col2\" class=\"data row17 col2\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row17_col3\" class=\"data row17 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row17_col4\" class=\"data row17 col4\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row17_col5\" class=\"data row17 col5\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_53915_row18_col0\" class=\"data row18 col0\" >20</td>\n",
       "                        <td id=\"T_53915_row18_col1\" class=\"data row18 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row18_col2\" class=\"data row18 col2\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row18_col3\" class=\"data row18 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row18_col4\" class=\"data row18 col4\" >0.520000</td>\n",
       "                        <td id=\"T_53915_row18_col5\" class=\"data row18 col5\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_53915_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_53915_row19_col0\" class=\"data row19 col0\" >21</td>\n",
       "                        <td id=\"T_53915_row19_col1\" class=\"data row19 col1\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row19_col2\" class=\"data row19 col2\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row19_col3\" class=\"data row19 col3\" >1.000000</td>\n",
       "                        <td id=\"T_53915_row19_col4\" class=\"data row19 col4\" >0.480000</td>\n",
       "                        <td id=\"T_53915_row19_col5\" class=\"data row19 col5\" >0.520000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd308d083d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a for loop that creates 20 Random Forrest models with increasingly larger depths.\n",
    "metrics2 = []\n",
    "forest_models = []\n",
    "for i in range(2, 22):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "    \n",
    "    y_predictions = forest.predict(X_train)\n",
    "    y_pred = forest.predict(X_validate)\n",
    "    \n",
    "    # Use the model\n",
    "    in_sample_accuracy = round(forest.score(X_train, y_train),3)\n",
    "    \n",
    "    out_of_sample_accuracy = round(forest.score(X_validate, y_validate),3)\n",
    "    \n",
    "    in_sample_recall = round(sklearn.metrics.recall_score(y_train, y_predictions, pos_label =0, average='micro'),3)\n",
    "    \n",
    "    out_of_sample_recall = round(sklearn.metrics.recall_score(y_validate, y_pred, pos_label =0, average='micro'),3)\n",
    "    \n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy,\n",
    "        \"train_recall\": in_sample_recall,\n",
    "        \"validate_recall\": out_of_sample_recall\n",
    "    }\n",
    "    \n",
    "    # This creates the df below\n",
    "    metrics2.append(output)\n",
    "    # tree_models will store all of my tree models incase i want them later\n",
    "    forest_models.append(forest)\n",
    "    \n",
    "    \n",
    "    \n",
    "forest_df = pd.DataFrame(metrics2)\n",
    "forest_df[\"accuracy_difference\"] = forest_df.train_accuracy - forest_df.validate_accuracy\n",
    "forest_df.style.highlight_min('accuracy_difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ff7c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), forest_models[forest_df.accuracy_difference.idxmin()], KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_stemmed_CV', 'SVC_stemmed_CV', 'Decision_tree_stemmed_CV', 'Random_forest_stemmed_CV', 'KNN_bigrams_stemmed_CV', 'Log_reg_stemmed_CV','SVC_stemmed_CV']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d871eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = vectorizer_split('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177f7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), forest_models[forest_df.accuracy_difference.idxmin()], KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_lemmatized_CV', 'SVC_lemmatized_CV', 'Decision_tree_lemmatized_CV', 'Random_forest_lemmatized_CV', 'KNN_bigrams_lemmatized_CV', 'Log_reg_lemmatized_CV','SVC_lemmatized_CV']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178728e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = tfidf_split('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0d1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), forest_models[forest_df.accuracy_difference.idxmin()], KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_stemmed_TFIDF', 'SVC_stemmed_TFIDF', 'Decision_tree_stemmed_TFIDF', 'Random_forest_stemmed_TFIDF', 'KNN_bigrams_stemmed_TFIDF', 'Log_reg_stemmed_TFIDF','SVC_stemmed_TFIDF']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4afca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = tfidf_split('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31ebe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), forest_models[forest_df.accuracy_difference.idxmin()], KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_lemmatized_TFIDF', 'SVC_lemmatized_TFIDF', 'Decision_tree_lemmatized_TFIDF', 'Random_forest_lemmatized_TFIDF', 'KNN_bigrams_lemmatized_TFIDF', 'Log_reg_lemmatized_TFIDF','SVC_lemmatized_TFIDF']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441c1da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_18ef2_row5_col2{\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_18ef2_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >model_name</th>        <th class=\"col_heading level0 col1\" >train_score</th>        <th class=\"col_heading level0 col2\" >validate_score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_18ef2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_18ef2_row0_col0\" class=\"data row0 col0\" >Naive_Bayes_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row0_col2\" class=\"data row0 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_18ef2_row1_col0\" class=\"data row1 col0\" >SVC_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row1_col2\" class=\"data row1 col2\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_18ef2_row2_col0\" class=\"data row2 col0\" >Decision_tree_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row2_col2\" class=\"data row2 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_18ef2_row3_col0\" class=\"data row3 col0\" >Random_forest_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row3_col1\" class=\"data row3 col1\" >0.862069</td>\n",
       "                        <td id=\"T_18ef2_row3_col2\" class=\"data row3 col2\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_18ef2_row4_col0\" class=\"data row4 col0\" >KNN_bigrams_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row4_col1\" class=\"data row4 col1\" >0.396552</td>\n",
       "                        <td id=\"T_18ef2_row4_col2\" class=\"data row4 col2\" >0.200000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_18ef2_row5_col0\" class=\"data row5 col0\" >Log_reg_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row5_col1\" class=\"data row5 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row5_col2\" class=\"data row5 col2\" >0.640000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_18ef2_row6_col0\" class=\"data row6 col0\" >SVC_stemmed_CV</td>\n",
       "                        <td id=\"T_18ef2_row6_col1\" class=\"data row6 col1\" >0.913793</td>\n",
       "                        <td id=\"T_18ef2_row6_col2\" class=\"data row6 col2\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_18ef2_row7_col0\" class=\"data row7 col0\" >Naive_Bayes_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row7_col2\" class=\"data row7 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_18ef2_row8_col0\" class=\"data row8 col0\" >SVC_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row8_col1\" class=\"data row8 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row8_col2\" class=\"data row8 col2\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_18ef2_row9_col0\" class=\"data row9 col0\" >Decision_tree_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row9_col1\" class=\"data row9 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row9_col2\" class=\"data row9 col2\" >0.560000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_18ef2_row10_col0\" class=\"data row10 col0\" >Random_forest_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row10_col1\" class=\"data row10 col1\" >0.810345</td>\n",
       "                        <td id=\"T_18ef2_row10_col2\" class=\"data row10 col2\" >0.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_18ef2_row11_col0\" class=\"data row11 col0\" >KNN_bigrams_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row11_col1\" class=\"data row11 col1\" >0.448276</td>\n",
       "                        <td id=\"T_18ef2_row11_col2\" class=\"data row11 col2\" >0.120000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_18ef2_row12_col0\" class=\"data row12 col0\" >Log_reg_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row12_col1\" class=\"data row12 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row12_col2\" class=\"data row12 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_18ef2_row13_col0\" class=\"data row13 col0\" >SVC_lemmatized_CV</td>\n",
       "                        <td id=\"T_18ef2_row13_col1\" class=\"data row13 col1\" >0.913793</td>\n",
       "                        <td id=\"T_18ef2_row13_col2\" class=\"data row13 col2\" >0.560000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_18ef2_row14_col0\" class=\"data row14 col0\" >Naive_Bayes_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row14_col1\" class=\"data row14 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row14_col2\" class=\"data row14 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_18ef2_row15_col0\" class=\"data row15 col0\" >SVC_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row15_col1\" class=\"data row15 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row15_col2\" class=\"data row15 col2\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_18ef2_row16_col0\" class=\"data row16 col0\" >Decision_tree_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row16_col1\" class=\"data row16 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row16_col2\" class=\"data row16 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_18ef2_row17_col0\" class=\"data row17 col0\" >Random_forest_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row17_col1\" class=\"data row17 col1\" >0.862069</td>\n",
       "                        <td id=\"T_18ef2_row17_col2\" class=\"data row17 col2\" >0.280000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_18ef2_row18_col0\" class=\"data row18 col0\" >KNN_bigrams_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row18_col1\" class=\"data row18 col1\" >0.758621</td>\n",
       "                        <td id=\"T_18ef2_row18_col2\" class=\"data row18 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_18ef2_row19_col0\" class=\"data row19 col0\" >Log_reg_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row19_col1\" class=\"data row19 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row19_col2\" class=\"data row19 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_18ef2_row20_col0\" class=\"data row20 col0\" >SVC_stemmed_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row20_col1\" class=\"data row20 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row20_col2\" class=\"data row20 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_18ef2_row21_col0\" class=\"data row21 col0\" >Naive_Bayes_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row21_col1\" class=\"data row21 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row21_col2\" class=\"data row21 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_18ef2_row22_col0\" class=\"data row22 col0\" >SVC_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row22_col1\" class=\"data row22 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row22_col2\" class=\"data row22 col2\" >0.560000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_18ef2_row23_col0\" class=\"data row23 col0\" >Decision_tree_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row23_col1\" class=\"data row23 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row23_col2\" class=\"data row23 col2\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_18ef2_row24_col0\" class=\"data row24 col0\" >Random_forest_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row24_col1\" class=\"data row24 col1\" >0.896552</td>\n",
       "                        <td id=\"T_18ef2_row24_col2\" class=\"data row24 col2\" >0.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_18ef2_row25_col0\" class=\"data row25 col0\" >KNN_bigrams_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row25_col1\" class=\"data row25 col1\" >0.775862</td>\n",
       "                        <td id=\"T_18ef2_row25_col2\" class=\"data row25 col2\" >0.480000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_18ef2_row26_col0\" class=\"data row26 col0\" >Log_reg_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row26_col1\" class=\"data row26 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row26_col2\" class=\"data row26 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ef2_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_18ef2_row27_col0\" class=\"data row27 col0\" >SVC_lemmatized_TFIDF</td>\n",
       "                        <td id=\"T_18ef2_row27_col1\" class=\"data row27 col1\" >1.000000</td>\n",
       "                        <td id=\"T_18ef2_row27_col2\" class=\"data row27 col2\" >0.400000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd32e445ca0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.style.highlight_max('validate_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04616a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'heatmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-76f5fea6d28e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mforest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mforest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy_difference\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mforest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'heatmap'"
     ]
    }
   ],
   "source": [
    "## Create a for loop that creates 20 Random Forrest models with increasingly larger depths.\n",
    "metrics2 = []\n",
    "forest_models = []\n",
    "for i in range(2, 22):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "    \n",
    "    y_predictions = forest.predict(X_train)\n",
    "    y_pred = forest.predict(X_validate)\n",
    "    \n",
    "    # Use the model\n",
    "    in_sample_accuracy = round(forest.score(X_train, y_train),3)\n",
    "    \n",
    "    out_of_sample_accuracy = round(forest.score(X_validate, y_validate),3)\n",
    "    \n",
    "    in_sample_recall = round(sklearn.metrics.recall_score(y_train, y_predictions, pos_label =0, average='micro'),3)\n",
    "    \n",
    "    out_of_sample_recall = round(sklearn.metrics.recall_score(y_validate, y_pred, pos_label =0, average='micro'),3)\n",
    "    \n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy,\n",
    "        \"train_recall\": in_sample_recall,\n",
    "        \"validate_recall\": out_of_sample_recall\n",
    "    }\n",
    "    \n",
    "    # This creates the df below\n",
    "    metrics2.append(output)\n",
    "    # tree_models will store all of my tree models incase i want them later\n",
    "    forest_models.append(forest)\n",
    "    \n",
    "    \n",
    "    \n",
    "forest_df = pd.DataFrame(metrics2)\n",
    "forest_df[\"accuracy_difference\"] = forest_df.train_accuracy - forest_df.validate_accuracy\n",
    "forest_df.style.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_models[forest_df.accuracy_difference.idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_df.accuracy_difference.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5b165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
