{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44ca195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from prepare import prepare\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# imports for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bab94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab49decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217978c",
   "metadata": {},
   "source": [
    "# Check out prepare for prepare details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b163b7c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train,validate,test = prepare(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a76e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Asabeneh/30-Days-Of-JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># 30 Days Of JavaScript\\n\\n| # Day |          ...</td>\n",
       "      <td>30 days javascript day topics 01 introductionr...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MrS0m30n3/youtube-dl-gui</td>\n",
       "      <td>Python</td>\n",
       "      <td>[![Donations Badge](https://yourdonation.rocks...</td>\n",
       "      <td>donations badgehttpsyourdonationrocksimagesbad...</td>\n",
       "      <td>donat badgehttpsyourdonationrocksimagesbadgesv...</td>\n",
       "      <td>donation badgehttpsyourdonationrocksimagesbadg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>statianzo/Fleck</td>\n",
       "      <td>C#</td>\n",
       "      <td>Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ddbourgin/numpy-ml</td>\n",
       "      <td>Python</td>\n",
       "      <td># numpy-ml\\nEver wish you had an inefficient b...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "      <td>numpyml ever wish ineffici somewhat legibl col...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mono/CppSharp</td>\n",
       "      <td>C#</td>\n",
       "      <td>CppSharp is a tool and set of libraries which ...</td>\n",
       "      <td>cppsharp tool set libraries facilitates usage ...</td>\n",
       "      <td>cppsharp tool set librari facilit usag nativ c...</td>\n",
       "      <td>cppsharp tool set library facilitates usage na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo    language  \\\n",
       "63  Asabeneh/30-Days-Of-JavaScript  JavaScript   \n",
       "18        MrS0m30n3/youtube-dl-gui      Python   \n",
       "72                 statianzo/Fleck          C#   \n",
       "12              ddbourgin/numpy-ml      Python   \n",
       "88                   mono/CppSharp          C#   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "63  # 30 Days Of JavaScript\\n\\n| # Day |          ...   \n",
       "18  [![Donations Badge](https://yourdonation.rocks...   \n",
       "72  Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...   \n",
       "12  # numpy-ml\\nEver wish you had an inefficient b...   \n",
       "88  CppSharp is a tool and set of libraries which ...   \n",
       "\n",
       "                                                clean  \\\n",
       "63  30 days javascript day topics 01 introductionr...   \n",
       "18  donations badgehttpsyourdonationrocksimagesbad...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish inefficient somewhat legible...   \n",
       "88  cppsharp tool set libraries facilitates usage ...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "63  30 day javascript day topic 01 introductionrea...   \n",
       "18  donat badgehttpsyourdonationrocksimagesbadgesv...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish ineffici somewhat legibl col...   \n",
       "88  cppsharp tool set librari facilit usag nativ c...   \n",
       "\n",
       "                                           lemmatized  \n",
       "63  30 day javascript day topic 01 introductionrea...  \n",
       "18  donation badgehttpsyourdonationrocksimagesbadg...  \n",
       "72  fleck build statushttpsciappveyorcomapiproject...  \n",
       "12  numpyml ever wish inefficient somewhat legible...  \n",
       "88  cppsharp tool set library facilitates usage na...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5200047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 6), (25, 6), (21, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027512fd",
   "metadata": {},
   "source": [
    "# No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b4b85",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5495f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    \n",
    "    ADDITIONAL_STOPWORDS = []\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a026e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C#</th>\n",
       "      <td>18</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>14</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>13</td>\n",
       "      <td>0.224138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>13</td>\n",
       "      <td>0.224138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n   percent\n",
       "C#          18  0.310345\n",
       "HTML        14  0.241379\n",
       "JavaScript  13  0.224138\n",
       "Python      13  0.224138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_counts_and_ratios(df, column):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a string of a single column\n",
    "    Returns a dataframe with absolute value counts and percentage value counts\n",
    "    \"\"\"\n",
    "    labels = pd.concat([df[column].value_counts(),\n",
    "                    df[column].value_counts(normalize=True)], axis=1)\n",
    "    labels.columns = ['n', 'percent']\n",
    "    labels\n",
    "    return labels\n",
    "\n",
    "show_counts_and_ratios(train, \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0983c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Asabeneh/30-Days-Of-JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># 30 Days Of JavaScript\\n\\n| # Day |          ...</td>\n",
       "      <td>30 days javascript day topics 01 introductionr...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "      <td>30 day javascript day topic 01 introductionrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MrS0m30n3/youtube-dl-gui</td>\n",
       "      <td>Python</td>\n",
       "      <td>[![Donations Badge](https://yourdonation.rocks...</td>\n",
       "      <td>donations badgehttpsyourdonationrocksimagesbad...</td>\n",
       "      <td>donat badgehttpsyourdonationrocksimagesbadgesv...</td>\n",
       "      <td>donation badgehttpsyourdonationrocksimagesbadg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>statianzo/Fleck</td>\n",
       "      <td>C#</td>\n",
       "      <td>Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "      <td>fleck build statushttpsciappveyorcomapiproject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ddbourgin/numpy-ml</td>\n",
       "      <td>Python</td>\n",
       "      <td># numpy-ml\\nEver wish you had an inefficient b...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "      <td>numpyml ever wish ineffici somewhat legibl col...</td>\n",
       "      <td>numpyml ever wish inefficient somewhat legible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mono/CppSharp</td>\n",
       "      <td>C#</td>\n",
       "      <td>CppSharp is a tool and set of libraries which ...</td>\n",
       "      <td>cppsharp tool set libraries facilitates usage ...</td>\n",
       "      <td>cppsharp tool set librari facilit usag nativ c...</td>\n",
       "      <td>cppsharp tool set library facilitates usage na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo    language  \\\n",
       "63  Asabeneh/30-Days-Of-JavaScript  JavaScript   \n",
       "18        MrS0m30n3/youtube-dl-gui      Python   \n",
       "72                 statianzo/Fleck          C#   \n",
       "12              ddbourgin/numpy-ml      Python   \n",
       "88                   mono/CppSharp          C#   \n",
       "\n",
       "                                      readme_contents  \\\n",
       "63  # 30 Days Of JavaScript\\n\\n| # Day |          ...   \n",
       "18  [![Donations Badge](https://yourdonation.rocks...   \n",
       "72  Fleck\\r\\n===\\r\\n\\r\\n[![Build status](https://c...   \n",
       "12  # numpy-ml\\nEver wish you had an inefficient b...   \n",
       "88  CppSharp is a tool and set of libraries which ...   \n",
       "\n",
       "                                                clean  \\\n",
       "63  30 days javascript day topics 01 introductionr...   \n",
       "18  donations badgehttpsyourdonationrocksimagesbad...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish inefficient somewhat legible...   \n",
       "88  cppsharp tool set libraries facilitates usage ...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "63  30 day javascript day topic 01 introductionrea...   \n",
       "18  donat badgehttpsyourdonationrocksimagesbadgesv...   \n",
       "72  fleck build statushttpsciappveyorcomapiproject...   \n",
       "12  numpyml ever wish ineffici somewhat legibl col...   \n",
       "88  cppsharp tool set librari facilit usag nativ c...   \n",
       "\n",
       "                                           lemmatized  \n",
       "63  30 day javascript day topic 01 introductionrea...  \n",
       "18  donation badgehttpsyourdonationrocksimagesbadg...  \n",
       "72  fleck build statushttpsciappveyorcomapiproject...  \n",
       "12  numpyml ever wish inefficient somewhat legible...  \n",
       "88  cppsharp tool set library facilitates usage na...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68269e79",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf65230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy:C# 31%\n"
     ]
    }
   ],
   "source": [
    "#Create a baseline model\n",
    "\n",
    "print(f'Baseline Accuracy:{train.language.value_counts().idxmax()} {round(max(train.language.value_counts()) / train.shape[0] *100)}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ed8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_split(x):   \n",
    "    vectorizer = CountVectorizer(binary = True, stop_words = 'english')\n",
    "    vectorizer.fit(list(train[x]))\n",
    "    X_train = vectorizer.transform(train[x])\n",
    "    X_validate= vectorizer.transform(validate[x])\n",
    "    X_test = vectorizer.transform(test[x])\n",
    "    return X_train.todense(),X_validate.todense(),X_test.todense()\n",
    "\n",
    "def tfidf_split(x):   \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(list(train[x]))\n",
    "    X_train = tfidf.transform(train[x])\n",
    "    X_validate= tfidf.transform(validate[x])\n",
    "    X_test = tfidf.transform(test[x])\n",
    "    return X_train.todense(),X_validate.todense(),X_test.todense()\n",
    "\n",
    "def test_a_model(X_train, y_train, X_validate, y_validate, model, model_name, score_df):\n",
    "    '''\n",
    "    Function takes in X and y train\n",
    "    X and y validate (or test) \n",
    "    A model with it's hyper parameters\n",
    "    And a df to store the scores \n",
    "    - Set up an empty dataframe with score_df first\n",
    "    - score_df = pd.DataFrame(columns = ['model_name', 'train_score', 'validate_score'])\n",
    "    '''\n",
    "    this_model = model\n",
    "\n",
    "    this_model.fit(X_train, y_train)\n",
    "\n",
    "    # Check with Validate\n",
    "\n",
    "    train_score = this_model.score(X_train, y_train)\n",
    "    \n",
    "    validate_score = this_model.score(X_validate, y_validate)\n",
    "    \n",
    "    model_dict = {'model_name': model_name, \n",
    "                  'train_score': train_score, \n",
    "                  'validate_score':validate_score}\n",
    "    score_df = score_df.append(model_dict, ignore_index = True)\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51bf5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.language\n",
    "y_validate = validate.language\n",
    "y_test = test.language\n",
    "X_train,X_validate,X_test = vectorizer_split('clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad67178",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = vectorizer_split('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b2b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(columns = ['model_name', 'train_score', 'validate_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5c425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_stemmed_CV', 'SVC_stemmed_CV', 'Decision_tree_stemmed_CV', 'Random_forest_stemmed_CV', 'KNN_bigrams_stemmed_CV', 'Log_reg_stemmed_CV','SVC_stemmed_CV']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb39e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = vectorizer_split('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4b7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_lemmatized_CV', 'SVC_lemmatized_CV', 'Decision_tree_lemmatized_CV', 'Random_forest_lemmatized_CV', 'KNN_bigrams_lemmatized_CV', 'Log_reg_lemmatized_CV','SVC_lemmatized_CV']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d5fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = tfidf_split('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ceb968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_stemmed_TFIDF', 'SVC_stemmed_TFIDF', 'Decision_tree_stemmed_TFIDF', 'Random_forest_stemmed_TFIDF', 'KNN_bigrams_stemmed_TFIDF', 'Log_reg_stemmed_TFIDF','SVC_stemmed_TFIDF']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9390a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test = tfidf_split('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1df4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# make a list of algorithms we want to try for our models\n",
    "model_list = [MultinomialNB(), LinearSVC(), DecisionTreeClassifier(), RandomForestClassifier(), KNeighborsClassifier(), LogisticRegression(), svm.SVC(C= 2, decision_function_shape='ovo')]\n",
    "\n",
    "# name the models\n",
    "model_names = ['Naive_Bayes_lemmatized_TFIDF', 'SVC_lemmatized_TFIDF', 'Decision_tree_lemmatized_TFIDF', 'Random_forest_lemmatized_TFIDF', 'KNN_bigrams_lemmatized_TFIDF', 'Log_reg_lemmatized_TFIDF','SVC_lemmatized_TFIDF']\n",
    "# Run the models\n",
    "for model, name in zip(model_list, model_names):\n",
    "    score_df = test_a_model(X_train, y_train, X_validate, y_validate, model, name, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9baf3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive_Bayes_stemmed_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC_stemmed_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision_tree_stemmed_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_forest_stemmed_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_bigrams_stemmed_CV</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Log_reg_stemmed_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_stemmed_CV</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive_Bayes_lemmatized_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_lemmatized_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision_tree_lemmatized_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random_forest_lemmatized_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN_bigrams_lemmatized_CV</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Log_reg_lemmatized_CV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC_lemmatized_CV</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Naive_Bayes_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision_tree_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random_forest_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNN_bigrams_stemmed_TFIDF</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Log_reg_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVC_stemmed_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Naive_Bayes_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Decision_tree_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random_forest_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNN_bigrams_lemmatized_TFIDF</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Log_reg_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC_lemmatized_TFIDF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name  train_score  validate_score\n",
       "0           Naive_Bayes_stemmed_CV     1.000000            0.52\n",
       "1                   SVC_stemmed_CV     1.000000            0.48\n",
       "2         Decision_tree_stemmed_CV     1.000000            0.44\n",
       "3         Random_forest_stemmed_CV     1.000000            0.44\n",
       "4           KNN_bigrams_stemmed_CV     0.396552            0.20\n",
       "5               Log_reg_stemmed_CV     1.000000            0.64\n",
       "6                   SVC_stemmed_CV     0.913793            0.60\n",
       "7        Naive_Bayes_lemmatized_CV     1.000000            0.52\n",
       "8                SVC_lemmatized_CV     1.000000            0.48\n",
       "9      Decision_tree_lemmatized_CV     1.000000            0.56\n",
       "10     Random_forest_lemmatized_CV     1.000000            0.40\n",
       "11       KNN_bigrams_lemmatized_CV     0.448276            0.12\n",
       "12           Log_reg_lemmatized_CV     1.000000            0.52\n",
       "13               SVC_lemmatized_CV     0.913793            0.56\n",
       "14       Naive_Bayes_stemmed_TFIDF     1.000000            0.40\n",
       "15               SVC_stemmed_TFIDF     1.000000            0.60\n",
       "16     Decision_tree_stemmed_TFIDF     1.000000            0.60\n",
       "17     Random_forest_stemmed_TFIDF     1.000000            0.28\n",
       "18       KNN_bigrams_stemmed_TFIDF     0.758621            0.52\n",
       "19           Log_reg_stemmed_TFIDF     1.000000            0.40\n",
       "20               SVC_stemmed_TFIDF     1.000000            0.40\n",
       "21    Naive_Bayes_lemmatized_TFIDF     1.000000            0.40\n",
       "22            SVC_lemmatized_TFIDF     1.000000            0.60\n",
       "23  Decision_tree_lemmatized_TFIDF     1.000000            0.60\n",
       "24  Random_forest_lemmatized_TFIDF     1.000000            0.44\n",
       "25    KNN_bigrams_lemmatized_TFIDF     0.758621            0.52\n",
       "26        Log_reg_lemmatized_TFIDF     1.000000            0.40\n",
       "27            SVC_lemmatized_TFIDF     1.000000            0.40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e04261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
